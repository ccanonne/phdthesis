\chapter*{Introduction} % Not a numbered chapter
\addcontentsline{toc}{chapter}{Introduction} % Puts your introduction in your table of contents even though we have used the asterisk in the \chapter command above.

\epigraph{``The thing can be done,'' said the Butcher, ``I think.\\
The thing must be done, I am sure.\\
The thing shall be done! Bring me paper and ink,\\
The best there is time to procure.''}{Lewis Carroll, \textit{The Hunting of the Snark}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

This dissertation revolves around discrete probability distributions: the wild and empirical ones, found in the ``real world''  wherever data can be found; or the familiar and abstract ones, which underly our (idealized) models of that very same world and let us reason about it. The practical details of the situations in which these distributions show up will not be of too much concern for us: instead, we will take their presence as a given, seeing them as an abstract source of data, values -- ``samples.''

And indeed, inferring \emph{information} from the probability distribution underlying available data is a fundamental problem in Statistics and data analysis, with applications and ramifications in countless other fields. One may want to approximate that distribution in its entirety; or, less ambitiously, to check whether it is consistent with a prespecified model; one may even only want to approximate some simple parameters such as its mean or first few moments. But this decades-old inference question, regardless of its specific variant, has undergone a significant shift these past few years: the amount of data to analyze has grown huge, and our distributions now are often over a \emph{very large} domain. So huge and so large, in fact, that the seasoned and well-studied methods from Statistics and learning theory are no longer practical; and one has to look for faster, more sample-efficient techniques and algorithms.

We may not be able to obtain these in general. But in many situations, we are only interested in figuring out some very specific information about our probability distribution: we made an assumption or formulated a hypothesis, and want to check whether we were right. To get this \emph{one bit} of information, and this bit only, it may just be possible to overcome the formidable complexity of the task. Understanding when it is, and how, is precisely what the field of distribution testing is about.

Distribution testing, as first explicitly introduced in~\cite{BFRSW:00},\footnote{From a historic perspective, the earlier~\cite{GGR:98} did briefly consider the model of distribution testing (Section 3.4.3);~\cite{BFRSW:00}, however, is the first work to study it specifically.}{} is a branch of property testing~\cite{RS:96,GGR:98}: in the latter, access to an unknown ``huge object'' is presented to an algorithm \textit{via} the ability to perform local ``inspections.'' By making only a small number of such queries to the object, the algorithm must determine with high probability whether the object exhibits some prespecified property of interest, or is \emph{far} from every object with the property. (For a more detailed presentation and overview of the field of property testing, the reader is referred to~\cite{Fischer:01,Ron:08,Ron:10,Goldreich:10,Gol:17,BY:17}.)

In distribution testing, this ``huge object'' is an unknown probability distribution (or a collection thereof) over some known (usually discrete) domain $\domain$; and the type of access granted to this distribution is (usually) access to independent samples drawn from that distribution. The question now becomes to bound the number of samples required to test a given statistical property -- as a function of the domain size and the ``farness'' parameter:
\begin{quote}
Given a property of distributions \property and access to an \emph{arbitrary} distribution $\D$, distinguish between the case that \textsf{(a)} $\D\in\property$, versus \textsf{(b)} $\totalvardist{\D}{\D^\prime} >\eps$ for all $\D^\prime\in\property$.
\end{quote}
Here, $\dtv$ denotes the total variation distance, also known as statistical distance. (We note that the focus is explicitly on the sample complexity: the running time of the algorithm is usually only a secondary concern, even though obtaining time-efficient testers is an explicit goal in many works.) Distribution testing has been a very active area over the past fifteen years, with a flurry\footnote{I immensely enjoy the word ``flurry.''}{} of variants and exciting developments: starting with~\cite{GRexp:00,BFRSW:10,BFFKRW:01}, this includes the testing of symmetric properties~\cite{RRSS:09,Valiant:11,VV:11:stoc,ValiantValiant:11}, of structured families~\cite{BKR:04,ILR:12,AD:15,Canonne:15,ADK:15,CDGR:16,Canonne:16}, as well as testing under some assumption on the unknown instance~\cite{RS:09,DDSVV:13,DKN:15,DKN:15:FOCS}. Tight upper and lower bounds on the sample complexity have been obtained for a vast number of properties such as uniformity, identity to a specified distribution, monotonicity, independence, and many more. We refer the reader of this thesis to the surveys~\cite{Rubinfeld:12:Survey,Canonne:15:Survey}, and the book~\cite{Gol:17}, for a more complete picture; and will focus afterwards on our narrow contribution to this field.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Our contributions}
Before delving into the specific and technical details, we provide a high-level overview of our contributions. As we shall see, they are organized in three main axes:

\subsection*{Beyond the standard distribution testing \emph{techniques}}  As aforementioned, distribution testing has been the focus of a significant body of works over recent years, culminating in a full understanding of the complexity for a large number of testing questions. However, while many of these questions have seen their sample complexity fully resolved, these advances have for a large part been the result of distinct, \textit{ad hoc} techniques tailored to the specific problems they were meant to solve. Overall, we still lack \emph{general} tools to tackle distribution testing questions -- both to establish (algorithmic) upper and (information-theoretic) lower bounds.

The first contribution of this thesis is to establish both general algorithmic frameworks (``Swiss Army knives'') and lower bound techniques (``easy reductions'') to attack these questions, in~\cref{chap:unified:ub,chap:unified:lb} respectively. Our results are widely applicable, and yield optimal or near-optimal bounds for a variety of (arguably) fundamental testing questions. In this sense, our work can be viewed as building up a user-friendly toolbox for distribution testing, which should come in handy to anyone in the field.

\subsection*{Beyond the \emph{standard} distribution testing techniques} One of the takeaway messages of the aforementioned recent flurry of results in distribution testing is that achieving a sublinear sample complexity with regard to the domain size \emph{is} possible for most properties of interest. Another takeaway, however, is that this sublinear sample complexity has to be \emph{polynomial} in this domain size $n$, i.e. of the form $n^{\bigOmega{1}}$ -- which, in many real-world settings, turns out to still be prohibitively high. Thus, it is reasonable to consider natural extensions of the standard ``sample-only'' model, where algorithms now get to have a stronger type of \emph{access} to the unknown probability distribution -- and see if this additional power allows them to achieve a significant better sample complexity. 

In~\cref{chap:newmodels} of this thesis, we introduce and study two such generalizations (along with some of their variants), which we argue can be implemented in practical situations. The main message is that, whenever these new models are applicable, one can perform much better than in the standard sampling model -- sometimes with a sample complexity \emph{independent} of the domain size. Moreover, such stronger models can also help us in understanding what exactly makes these questions ``hard'' in the standard sampling model in the first place, and therefore hopefully guide implementations even of ``standard'' testing algorithms by adapting them on a case-by-case basis.\cmargin{Is it too much?}

\subsection*{Beyond the standard distribution \emph{testing} techniques} So far, we stayed within the realm of distribution testing: focusing on a specific property of distributions, how to decide whether the unknown one we have access to indeed satisfies this property. This, however, may not be the end goal: for instance, what if after running such a test, we knew the distribution is \emph{close} to having that property -- yet are not guaranteed it does \emph{exactly}? What if a subsequent algorithm, or application, requires such a guarantee? To handle such questions, we introduce in~\cref{chap:correction} the notion of a \emph{sampling corrector}, which (broadly speaking) acts as a filter between a source of imperfect samples and an algorithm to provide access to ``corrected samples'' -- whose distribution is close to the original one, but now does satisfy the property of interest. We further explore this new paradigm of simple correction (and its weaker variant of sampling \emph{improvement}), and study its connections to distribution testing and learning -- showing two-way implications that may prove fruitful in establishing new upper and lower bound in either direction. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Organization of the dissertation}

In~\cref{chap:preliminaries}, we lay down the necessary notation and definitions that will be used throughout this thesis, and state some results from the literature that we shall need afterwards. We will also prove there several simple results that will be relied upon in the other chapters, and more generally set up the board and pieces.~\cref{chap:unified:ub} then will be concerned with general strategies to play the game; or, put differently, with unified frameworks to obtain algorithmic \emph{upper bounds} on distribution testing questions. In more detail,~\cref{sec:shaperestrictions} describes a unified approach for testing membership in classes of distributions, particularly relevant for classes of \emph{shape-restricted} distributions; while~\cref{sec:fourier} contains a different approach for this question, well-suited for those classes of distributions which enjoy ``nice'' Fourier spectra. The first is based on joint work with Ilias Diakonikolas, Themis Gouleakis, and Ronitt Rubinfeld~\cite{CDGR:16}, and the second on the paper~\cite{CanonneDS:17} with Ilias Diakonikolas and Alistair Stewart.

In~\cref{chap:unified:lb}, we complement these algorithmic frameworks by describing new general approaches to obtaining information-theoretic \emph{lower bounds} in distribution testing.~\cref{sec:learningreductions}, based on~\cite{CDGR:16}, describes a reduction technique which allows us to lift hardness of testing a sub-property $\property'\subseteq\property$ to that of testing $\property$ itself, modulo a mild learnability condition on the latter. As a corollary, we obtain new (as well as previously known) lower bounds for many distribution classes, in a clean and unified way.~\cref{sec:communication} (based on the paper~\cite{BCG:17} with Eric Blais and Tom Gur) then provides another framework  to easily establish distribution testing lower bounds, this time by carrying over lower bounds from \emph{communication complexity}. We show how this reduction from communication complexity, besides enabling us to easily derive lower bounds for a variety of distribution testing questions, can also shed light on existing results, leading to an unexpected connection between distribution testing and the seemingly unrelated field of interpolation theory.

In these two chapters, we were concerned with the ``standard'' setting of distribution testing, which only assumes access to independent samples; and developed general methods to tackle questions in this setting. In~\cref{chap:newmodels}, we take a different path: instead of finding new strategies to play the game, we change the \emph{rules} themselves -- granting the testing algorithms a more powerful type of access to the unknown distribution. Based on a work with Dana Ron and Rocco Servedio~\cite{CRS:15},~\cref{sec:conditional} introduces and studies the \emph{conditional sampling model}, in which the algorithm can get samples from the underlying probability distribution conditioned on subsets of events of its choosing. In~\cref{sec:extended}, we define and study two different settings, the \emph{dual access} and \emph{cumulative dual access} models, in which one can both draw independent samples from the distribution and query the value on any point of the domain of either its probability mass function or cumulative distribution function. (This is based on the paper~\cite{CR:14}, with Ronitt Rubinfeld.) Both sections thus consider testing algorithms that are at least as powerful as those from the standard sampling setting; the question is to quantify \emph{how much} more powerful these algorithms can be, and what limitations remain.

Finally, in~\cref{chap:correction} we venture out of property testing to explore a different -- albeit related -- paradigm: that of distribution \emph{correcting}. Changing now the \emph{goal} of the game, we introduce the notion of sampling corrector: granted access to independent samples from a probability distribution only \emph{close} to having some property $\property$ of interest, one must provide access to samples from a ``corrected'' distribution which, while still being close to the original distribution, does satisfy $\property$. We prove general results on this new algorithmic primitive, and study its relation to both distribution learning and testing; before focusing specifically on correction of a well-studied property of distributions, monotonicity. This last chapter contains material from~\cite{CGR:16}, joint work with Themis Gouleakis and Ronitt Rubinfeld.
